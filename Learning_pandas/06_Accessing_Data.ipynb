{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas and numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set some pandas options for controlling output\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading from CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The sample CSV data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date,Open,High,Low,Close,Volume,Adj Close\n",
      "2014-07-21,83.46,83.53,81.81,81.93,2359300,81.93\n",
      "2014-07-18,83.30,83.40,82.52,83.35,4020800,83.35\n",
      "2014-07-17,84.35,84.63,83.33,83.63,1974000,83.63\n",
      "2014-07-16,83.77,84.91,83.66,84.91,1755600,84.91\n"
     ]
    }
   ],
   "source": [
    "# view the first five lines of data/msft.csv\n",
    "!head -n 5 data/msft.csv # mac or Linux\n",
    "# type data/msft.csv # on windows, but shows the entire file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a CSV into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   2015/09/02  5.85  6.44  5.81  6.41    522251683  4716634624.00\n",
       "0  2015/09/07  6.25  6.25  5.64  5.70  252584540.0   2.191700e+09\n",
       "1  2015/09/08  5.64  6.01  5.54  5.74  155104868.0   1.314949e+09\n",
       "2  2015/09/09  5.75  5.80  5.68  5.76  136093762.0   1.151730e+09\n",
       "3  2015/09/10  5.70  5.88  5.67  5.86  126104722.0   1.075610e+09\n",
       "4  2015/09/11  5.81  5.87  5.77  5.84   59208367.0   5.074036e+08"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in msft.csv into a DataFrame\n",
    "#msft = pd.read_csv(\"data/msft.csv\")\n",
    "msft = pd.read_csv(\"data/SH600016.csv\",skiprows=2,encoding=\"gbk\")\n",
    "msft.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying the index column when reading a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            日期\\t    开盘\\t    最高\\t    最低\\t    收盘\\t    成交量\\t    成交额\n",
       "2015/09/02 5.85 6.44 5.81 6.41 522251683.0                                       4.716635e+09   \n",
       "2015/09/07 6.25 6.25 5.64 5.70 252584540.0                                       2.191700e+09   \n",
       "2015/09/08 5.64 6.01 5.54 5.74 155104868.0                                       1.314949e+09   \n",
       "2015/09/09 5.75 5.80 5.68 5.76 136093762.0                                       1.151730e+09   \n",
       "2015/09/10 5.70 5.88 5.67 5.86 126104722.0                                       1.075610e+09   "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use column 0 as the index\n",
    "msft = pd.read_csv(\"data/SH600016.csv\", skiprows=1, encoding=\"gbk\")\n",
    "msft.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data type inference and specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "日期\\t    开盘\\t    最高\\t    最低\\t    收盘\\t    成交量\\t    成交额    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the types of the columns in this DataFrame\n",
    "msft.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date          object\n",
       "Open         float64\n",
       "High         float64\n",
       "Low          float64\n",
       "Close        float64\n",
       "Volume       float64\n",
       "Adj Close    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify that the Volume column should be a float64\n",
    "msft = pd.read_csv(\"data/msft.csv\", \n",
    "                   dtype = { 'Volume' : np.float64})\n",
    "msft.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             open   high    low  close   volume  volume_value\n",
       "2014-07-18  83.30  83.40  82.52  83.35  4020800         83.35\n",
       "2014-07-17  84.35  84.63  83.33  83.63  1974000         83.63\n",
       "2014-07-16  83.77  84.91  83.66  84.91  1755600         84.91\n",
       "2014-07-15  84.30  84.38  83.20  83.58  1874700         83.58\n",
       "2014-07-14  83.66  84.64  83.11  84.40  1432100         84.40\n",
       "...           ...    ...    ...    ...      ...           ...\n",
       "2000-01-07  48.55  50.35  47.80  50.00  4621200         19.48\n",
       "2000-01-06  46.78  48.35  46.28  48.03  3306100         18.72\n",
       "2000-01-05  46.94  47.50  45.92  46.75  4809900         18.22\n",
       "2000-01-04  49.80  49.80  47.72  47.85  4489500         18.65\n",
       "2000-01-03  52.70  53.20  49.60  49.75  3137300         19.39\n",
       "\n",
       "[3766 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify a new set of names for the columns\n",
    "# all lower case, remove space in Adj Close\n",
    "# also, header=0 skips the header row\n",
    "#df = pd.read_csv(\"data/msft.csv\", \n",
    "#                 header=0,\n",
    "#                 names=['open', 'high', 'low', \n",
    "#                        'close', 'volume', 'adjclose'])\n",
    "df = pd.read_csv(\"data/msft.csv\", skiprows=2, names=['open','high','low','close','volume','volume_value'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying specific columns to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             open   high    low  close   volume  volume_value\n",
       "date                                                         \n",
       "2014-07-18  83.30  83.40  82.52  83.35  4020800         83.35\n",
       "2014-07-17  84.35  84.63  83.33  83.63  1974000         83.63\n",
       "2014-07-16  83.77  84.91  83.66  84.91  1755600         84.91\n",
       "2014-07-15  84.30  84.38  83.20  83.58  1874700         83.58\n",
       "2014-07-14  83.66  84.64  83.11  84.40  1432100         84.40"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data only in the Date and Close columns\n",
    "# and index by the Date column\n",
    "#df2 = pd.read_csv(\"data/msft.csv\", usecols=['Date', 'Close'], index_col=['Date'])\n",
    "df2 = pd.read_csv(\"data/msft.csv\", skiprows=2, names=['date','open','high','low','close','volume','volume_value'],index_col=['date'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving a DataFrame to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df2 to a new csv file\n",
    "# also specify naming the index as date\n",
    "df2.to_csv(\"data/msft_modified.csv\", index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date,open,high,low,close,volume,volume_value\n",
      "2014-07-18,83.3,83.4,82.52,83.35,4020800,83.35\n",
      "2014-07-17,84.35,84.63,83.33,83.63,1974000,83.63\n",
      "2014-07-16,83.77,84.91,83.66,84.91,1755600,84.91\n",
      "2014-07-15,84.3,84.38,83.2,83.58,1874700,83.58\n",
      "2014-07-14,83.66,84.64,83.11,84.4,1432100,84.4\n",
      "2014-07-11,83.55,83.98,82.85,83.35,2001400,83.35\n",
      "2014-07-10,85.2,85.57,83.36,83.42,2713300,83.42\n",
      "2014-07-09,84.83,85.79,84.76,85.5,1540700,85.5\n",
      "2014-07-08,86.29,86.57,84.69,84.69,2164000,84.69\n"
     ]
    }
   ],
   "source": [
    "# view the start of the file just saved\n",
    "!head data/msft_modified.csv\n",
    "#type data/msft_modified.csv # windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General field-delimited data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Date   Open   High    Low  Close   Volume  Adj Close\n",
       "0  2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
       "1  2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n",
       "2  2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63\n",
       "3  2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91\n",
       "4  2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use read_table with sep=',' to read a CSV\n",
    "df = pd.read_csv(\"data/msft.csv\", sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Date|Open|High|Low|Close|Volume|Adj Close\n",
      "0|2014-07-21|83.46|83.53|81.81|81.93|2359300|81.93\n",
      "1|2014-07-18|83.3|83.4|82.52|83.35|4020800|83.35\n",
      "2|2014-07-17|84.35|84.63|83.33|83.63|1974000|83.63\n",
      "3|2014-07-16|83.77|84.91|83.66|84.91|1755600|84.91\n"
     ]
    }
   ],
   "source": [
    "# save as pipe delimited\n",
    "df.to_csv(\"data/msft_piped.txt\", sep='|')\n",
    "# check that it worked\n",
    "!head -n 5 data/msft_piped.txt # osx or Linux\n",
    "# type data/psft_piped.txt # on windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling variants of formats in field-delimited data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is fun because the data does not start on the first line\n",
      "Date,Open,High,Low,Close,Volume,Adj Close\n",
      "\n",
      "And there is space between the header row and data\n",
      "2014-07-21,83.46,83.53,81.81,81.93,2359300,81.93\n",
      "2014-07-18,83.30,83.40,82.52,83.35,4020800,83.35\n",
      "2014-07-17,84.35,84.63,83.33,83.63,1974000,83.63\n",
      "2014-07-16,83.77,84.91,83.66,84.91,1755600,84.91\n",
      "2014-07-15,84.30,84.38,83.20,83.58,1874700,83.58\n",
      "2014-07-14,83.66,84.64,83.11,84.40,1432100,84.40\n"
     ]
    }
   ],
   "source": [
    "# messy file\n",
    "!head data/msft2.csv # osx or Linux\n",
    "# type data/msft2.csv # windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Date   Open   High    Low  Close   Volume  Adj Close\n",
       "0  2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
       "1  2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n",
       "2  2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63\n",
       "3  2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91\n",
       "4  2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58\n",
       "5  2014-07-14  83.66  84.64  83.11  84.40  1432100      84.40\n",
       "6  2014-07-11  83.55  83.98  82.85  83.35  2001400      83.35\n",
       "7  2014-07-10  85.20  85.57  83.36  83.42  2713300      83.42\n",
       "8  2014-07-09  84.83  85.79  84.76  85.50  1540700      85.50"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read, but skip rows 0, 2 and 3\n",
    "df = pd.read_csv(\"data/msft2.csv\", skiprows=[0, 2, 3])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date,Open,High,Low,Close,Volume,Adj Close\n",
      "2014-07-21,83.46,83.53,81.81,81.93,2359300,81.93\n",
      "2014-07-18,83.30,83.40,82.52,83.35,4020800,83.35\n",
      "\n",
      "Uh oh, there is stuff at the end."
     ]
    }
   ],
   "source": [
    "# another messy file, with the mess at the end\n",
    "!cat data/msft_with_footer.csv # osx or Linux\n",
    "# type data/msft_with_footer.csv # windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date   Open   High    Low  Close   Volume  Adj Close\n",
      "0  2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
      "1  2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file while skipping the last two lines\n",
    "df = pd.read_csv(\"data/msft_with_footer.csv\", skipfooter=2, engine='python')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Date   Open   High    Low  Close   Volume  Adj Close\n",
       "0  2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
       "1  2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n",
       "2  2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only process the first three rows\n",
    "pd.read_csv(\"data/msft.csv\", nrows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             open   high    low  close      vol  adjclose\n",
       "2014-03-03  80.35  81.31  79.91  79.97  5004100     77.40\n",
       "2014-02-28  82.40  83.42  82.17  83.42  2853200     80.74\n",
       "2014-02-27  84.06  84.63  81.63  82.00  3676800     79.36\n",
       "2014-02-26  82.92  84.03  82.43  83.81  2623600     81.12\n",
       "2014-02-25  83.80  83.80  81.72  83.08  3579100     80.41"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip 100 lines, then only process the next five\n",
    "pd.read_csv(\"data/msft.csv\", skiprows=100, nrows=5, \n",
    "            header=0,\n",
    "            names=['open', 'high', 'low', 'close', 'vol', \n",
    "                   'adjclose'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and writing data in Excel format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume  Adj Close\n",
       "0 2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
       "1 2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n",
       "2 2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63\n",
       "3 2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91\n",
       "4 2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read excel file\n",
    "# only reads first sheet (msft in this case)\n",
    "df = pd.read_excel(\"data/stocks.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close    Volume  Adj Close\n",
       "0 2014-07-21  94.99  95.00  93.72  93.94  38887700      93.94\n",
       "1 2014-07-18  93.62  94.74  93.02  94.43  49898600      94.43\n",
       "2 2014-07-17  95.03  95.28  92.57  93.09  57152000      93.09\n",
       "3 2014-07-16  96.97  97.10  94.74  94.78  53396300      94.78\n",
       "4 2014-07-15  96.80  96.85  95.03  95.32  45477900      95.32"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read from the aapl worksheet\n",
    "aapl = pd.read_excel(\"data/stocks.xlsx\", sheet_name='aapl')\n",
    "aapl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to an Excel file in worksheet 'Sheet1'\n",
    "df.to_excel(\"data/stocks2.xlsx\", sheet_name='Sheet1', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to an Excel file in worksheet 'MSFT'\n",
    "df.to_excel(\"data/stocks_msft.xlsx\", sheet_name='MSFT', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write multiple sheets to an Excel file using openpyxl\n",
    "with ExcelWriter(\"data/all_stocks.xlsx\", engine='openpyxl') as writer:\n",
    "    aapl.to_excel(writer, sheet_name='AAPL', index=False)\n",
    "    df.to_excel(writer, sheet_name='MSFT', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to xlsx\n",
    "df.to_excel(\"data/msft2.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and writing JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Date\":{\"0\":1405900800000,\"1\":1405641600000,\"2\":1405555200000,\"3\":1405468800000,\"4\":1405382400000},\"Open\":{\"0\":83.46,\"1\":83.3,\"2\":84.35,\"3\":83.77,\"4\":84.3},\"High\":{\"0\":83.53,\"1\":83.4,\"2\":84.63,\"3\":84.91,\"4\":84.38},\"Low\":{\"0\":81.81,\"1\":82.52,\"2\":83.33,\"3\":83.66,\"4\":83.2},\"Close\":{\"0\":81.93,\"1\":83.35,\"2\":83.63,\"3\":84.91,\"4\":83.58},\"Volume\":{\"0\":2359300,\"1\":4020800,\"2\":1974000,\"3\":1755600,\"4\":1874700},\"Adj Close\":{\"0\":81.93,\"1\":83.35,\"2\":83.63,\"3\":84.91,\"4\":83.58}}"
     ]
    }
   ],
   "source": [
    "# wirite the excel data to a JSON file\n",
    "df.head().to_json(\"data/stocks.json\")\n",
    "!cat data/stocks.json # osx or Linux\n",
    "#type data/stocks.json # windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume  Adj Close\n",
       "0 2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
       "1 2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n",
       "2 2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63\n",
       "3 2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91\n",
       "4 2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data in from JSON\n",
    "df_from_json = pd.read_json(\"data/stocks.json\")\n",
    "df_from_json.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading HTML data from the Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No tables found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://www.fdic.gov/bank/individual/failed/banklist.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Read the HTML tables from the URL\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m banks \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_html(url)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Examine a subset of the first table read\u001b[39;00m\n\u001b[1;32m      8\u001b[0m subset \u001b[38;5;241m=\u001b[39m banks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m4\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/html.py:1098\u001b[0m, in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only)\u001b[0m\n\u001b[1;32m   1094\u001b[0m validate_header_arg(header)\n\u001b[1;32m   1096\u001b[0m io \u001b[38;5;241m=\u001b[39m stringify_path(io)\n\u001b[0;32m-> 1098\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parse(\n\u001b[1;32m   1099\u001b[0m     flavor\u001b[38;5;241m=\u001b[39mflavor,\n\u001b[1;32m   1100\u001b[0m     io\u001b[38;5;241m=\u001b[39mio,\n\u001b[1;32m   1101\u001b[0m     match\u001b[38;5;241m=\u001b[39mmatch,\n\u001b[1;32m   1102\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   1103\u001b[0m     index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m   1104\u001b[0m     skiprows\u001b[38;5;241m=\u001b[39mskiprows,\n\u001b[1;32m   1105\u001b[0m     parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[1;32m   1106\u001b[0m     thousands\u001b[38;5;241m=\u001b[39mthousands,\n\u001b[1;32m   1107\u001b[0m     attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1108\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   1109\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   1110\u001b[0m     converters\u001b[38;5;241m=\u001b[39mconverters,\n\u001b[1;32m   1111\u001b[0m     na_values\u001b[38;5;241m=\u001b[39mna_values,\n\u001b[1;32m   1112\u001b[0m     keep_default_na\u001b[38;5;241m=\u001b[39mkeep_default_na,\n\u001b[1;32m   1113\u001b[0m     displayed_only\u001b[38;5;241m=\u001b[39mdisplayed_only,\n\u001b[1;32m   1114\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/html.py:926\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m retained \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retained\n\u001b[1;32m    928\u001b[0m ret \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/html.py:906\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m p \u001b[38;5;241m=\u001b[39m parser(io, compiled_match, attrs, encoding, displayed_only)\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 906\u001b[0m     tables \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mparse_tables()\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io\u001b[38;5;241m.\u001b[39mseekable():\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/html.py:222\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_tables(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_doc(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs)\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/html.py:552\u001b[0m, in \u001b[0;36m_BeautifulSoupHtml5LibFrameParser._parse_tables\u001b[0;34m(self, doc, match, attrs)\u001b[0m\n\u001b[1;32m    549\u001b[0m tables \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mfind_all(element_name, attrs\u001b[38;5;241m=\u001b[39mattrs)\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tables:\n\u001b[0;32m--> 552\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo tables found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    554\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    555\u001b[0m unique_tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: No tables found"
     ]
    }
   ],
   "source": [
    "# The URL to read\n",
    "url = \"http://www.fdic.gov/bank/individual/failed/banklist.html\"\n",
    "\n",
    "# Read the HTML tables from the URL\n",
    "banks = pd.read_html(url)\n",
    "\n",
    "# Examine a subset of the first table read\n",
    "subset = banks[0].iloc[0:5, 0:4]\n",
    "\n",
    "# Display the subset\n",
    "print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table border=\"1\" class=\"dataframe\">\n",
      "  <thead>\n",
      "    <tr style=\"text-align: right;\">\n",
      "      <th></th>\n",
      "      <th>Date</th>\n",
      "      <th>Open</th>\n",
      "      <th>High</th>\n",
      "      <th>Low</th>\n",
      "      <th>Close</th>\n",
      "      <th>Volume</th>\n",
      "      <th>Adj Close</th>\n",
      "    </tr>\n",
      "  </thead>\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <th>0</th>\n",
      "      <td>2014-07-21</td>\n",
      "      <td>83.46</td>\n",
      "      <td>83.53</td>\n",
      "      <td>81.81</td>\n",
      "      <td>81.93</td>\n",
      "      <td>2359300</td>\n",
      "      <td>81.93</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>1</th>\n",
      "      <td>2014-07-18</td>\n",
      "      <td>83.30</td>\n"
     ]
    }
   ],
   "source": [
    "# read the stock data\n",
    "df = pd.read_excel(\"data/stocks.xlsx\")\n",
    "# write the first two rows to HTML\n",
    "df.head(2).to_html(\"data/stocks.html\")\n",
    "# check the first 28 lines of the output\n",
    "!head -n 28 data/stocks.html # max or Linux\n",
    "# type data/stocks.html # window, but prints the entire file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and writing HDF5 format files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.io.pytables.HDFStore'>\n",
       "File path: data/store.h5"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seed for replication\n",
    "np.random.seed(123456)\n",
    "# create a DataFrame of dates and random numbers in three columns\n",
    "df = pd.DataFrame(np.random.randn(8, 3), \n",
    "                  index=pd.date_range('1/1/2000', periods=8),\n",
    "                  columns=['A', 'B', 'C'])\n",
    "\n",
    "# create HDF5 store\n",
    "store = pd.HDFStore('data/store.h5')\n",
    "store['df'] = df # persisting happened here\n",
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   A         B         C\n",
       "2000-01-01  0.469112 -0.282863 -1.509059\n",
       "2000-01-02 -1.135632  1.212112 -0.173215\n",
       "2000-01-03  0.119209 -1.044236 -0.861849\n",
       "2000-01-04 -2.104569 -0.494929  1.071804\n",
       "2000-01-05  0.721555 -0.706771 -1.039575\n",
       "2000-01-06  0.271860 -0.424972  0.567020\n",
       "2000-01-07  0.276232 -1.087401 -0.673690\n",
       "2000-01-08  0.113648 -1.478427  0.524988"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data from HDF5\n",
    "store = pd.HDFStore(\"data/store.h5\")\n",
    "df = store['df']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Passing an incorrect value to a table column. Expected a Col (or subclass) instance and got: \"ObjectAtom()\". Please make use of the Col(), or descendant, constructor to properly initialize columns.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Persist the change by saving the DataFrame to an HDF5 store using the 'table' format\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mHDFStore(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/store1.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m store:\n\u001b[0;32m---> 10\u001b[0m     store\u001b[38;5;241m.\u001b[39mput(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m'\u001b[39m, df, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Load the store and show the first two rows to verify persistence\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mHDFStore(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/store1.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m store:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/pytables.py:1122\u001b[0m, in \u001b[0;36mHDFStore.put\u001b[0;34m(self, key, value, format, index, append, complib, complevel, min_itemsize, nan_rep, data_columns, encoding, errors, track_times, dropna)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mio.hdf.default_format\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfixed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_format(\u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m-> 1122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_to_group(\n\u001b[1;32m   1123\u001b[0m     key,\n\u001b[1;32m   1124\u001b[0m     value,\n\u001b[1;32m   1125\u001b[0m     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m,\n\u001b[1;32m   1126\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   1127\u001b[0m     append\u001b[38;5;241m=\u001b[39mappend,\n\u001b[1;32m   1128\u001b[0m     complib\u001b[38;5;241m=\u001b[39mcomplib,\n\u001b[1;32m   1129\u001b[0m     complevel\u001b[38;5;241m=\u001b[39mcomplevel,\n\u001b[1;32m   1130\u001b[0m     min_itemsize\u001b[38;5;241m=\u001b[39mmin_itemsize,\n\u001b[1;32m   1131\u001b[0m     nan_rep\u001b[38;5;241m=\u001b[39mnan_rep,\n\u001b[1;32m   1132\u001b[0m     data_columns\u001b[38;5;241m=\u001b[39mdata_columns,\n\u001b[1;32m   1133\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   1134\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   1135\u001b[0m     track_times\u001b[38;5;241m=\u001b[39mtrack_times,\n\u001b[1;32m   1136\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[1;32m   1137\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/pytables.py:1772\u001b[0m, in \u001b[0;36mHDFStore._write_to_group\u001b[0;34m(self, key, value, format, axes, index, append, complib, complevel, fletcher32, min_itemsize, chunksize, expectedrows, dropna, nan_rep, data_columns, encoding, errors, track_times)\u001b[0m\n\u001b[1;32m   1769\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompression not supported on Fixed format stores\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1771\u001b[0m \u001b[38;5;66;03m# write the object\u001b[39;00m\n\u001b[0;32m-> 1772\u001b[0m s\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[1;32m   1773\u001b[0m     obj\u001b[38;5;241m=\u001b[39mvalue,\n\u001b[1;32m   1774\u001b[0m     axes\u001b[38;5;241m=\u001b[39maxes,\n\u001b[1;32m   1775\u001b[0m     append\u001b[38;5;241m=\u001b[39mappend,\n\u001b[1;32m   1776\u001b[0m     complib\u001b[38;5;241m=\u001b[39mcomplib,\n\u001b[1;32m   1777\u001b[0m     complevel\u001b[38;5;241m=\u001b[39mcomplevel,\n\u001b[1;32m   1778\u001b[0m     fletcher32\u001b[38;5;241m=\u001b[39mfletcher32,\n\u001b[1;32m   1779\u001b[0m     min_itemsize\u001b[38;5;241m=\u001b[39mmin_itemsize,\n\u001b[1;32m   1780\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m   1781\u001b[0m     expectedrows\u001b[38;5;241m=\u001b[39mexpectedrows,\n\u001b[1;32m   1782\u001b[0m     dropna\u001b[38;5;241m=\u001b[39mdropna,\n\u001b[1;32m   1783\u001b[0m     nan_rep\u001b[38;5;241m=\u001b[39mnan_rep,\n\u001b[1;32m   1784\u001b[0m     data_columns\u001b[38;5;241m=\u001b[39mdata_columns,\n\u001b[1;32m   1785\u001b[0m     track_times\u001b[38;5;241m=\u001b[39mtrack_times,\n\u001b[1;32m   1786\u001b[0m )\n\u001b[1;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, Table) \u001b[38;5;129;01mand\u001b[39;00m index:\n\u001b[1;32m   1789\u001b[0m     s\u001b[38;5;241m.\u001b[39mcreate_index(columns\u001b[38;5;241m=\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/pytables.py:4321\u001b[0m, in \u001b[0;36mAppendableTable.write\u001b[0;34m(self, obj, axes, append, complib, complevel, fletcher32, min_itemsize, chunksize, expectedrows, dropna, nan_rep, data_columns, track_times)\u001b[0m\n\u001b[1;32m   4318\u001b[0m     options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack_times\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m track_times\n\u001b[1;32m   4320\u001b[0m     \u001b[38;5;66;03m# create the table\u001b[39;00m\n\u001b[0;32m-> 4321\u001b[0m     table\u001b[38;5;241m.\u001b[39m_handle\u001b[38;5;241m.\u001b[39mcreate_table(table\u001b[38;5;241m.\u001b[39mgroup, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m   4323\u001b[0m \u001b[38;5;66;03m# update my info\u001b[39;00m\n\u001b[1;32m   4324\u001b[0m table\u001b[38;5;241m.\u001b[39mattrs\u001b[38;5;241m.\u001b[39minfo \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39minfo\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tables/file.py:1016\u001b[0m, in \u001b[0;36mFile.create_table\u001b[0;34m(self, where, name, description, title, filters, expectedrows, chunkshape, byteorder, createparents, obj, track_times)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid table description: None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1014\u001b[0m _checkfilters(filters)\n\u001b[0;32m-> 1016\u001b[0m ptobj \u001b[38;5;241m=\u001b[39m Table(parentnode, name,\n\u001b[1;32m   1017\u001b[0m               description\u001b[38;5;241m=\u001b[39mdescription, title\u001b[38;5;241m=\u001b[39mtitle,\n\u001b[1;32m   1018\u001b[0m               filters\u001b[38;5;241m=\u001b[39mfilters, expectedrows\u001b[38;5;241m=\u001b[39mexpectedrows,\n\u001b[1;32m   1019\u001b[0m               chunkshape\u001b[38;5;241m=\u001b[39mchunkshape, byteorder\u001b[38;5;241m=\u001b[39mbyteorder,\n\u001b[1;32m   1020\u001b[0m               track_times\u001b[38;5;241m=\u001b[39mtrack_times)\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1023\u001b[0m     ptobj\u001b[38;5;241m.\u001b[39mappend(obj)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tables/table.py:745\u001b[0m, in \u001b[0;36mTable.__init__\u001b[0;34m(self, parentnode, name, description, title, filters, expectedrows, chunkshape, byteorder, _log, track_times)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;66;03m# Initialize this object in case is a new Table\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \n\u001b[1;32m    742\u001b[0m \u001b[38;5;66;03m# Try purely descriptive description objects.\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(description, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;66;03m# Dictionary case\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription \u001b[38;5;241m=\u001b[39m Description(description,\n\u001b[1;32m    746\u001b[0m                                    ptparams\u001b[38;5;241m=\u001b[39mparentnode\u001b[38;5;241m.\u001b[39m_v_file\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mtype\u001b[39m(description) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mtype\u001b[39m(IsDescription)\n\u001b[1;32m    748\u001b[0m               \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(description, IsDescription)):\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;66;03m# IsDescription subclass case\u001b[39;00m\n\u001b[1;32m    750\u001b[0m     descr \u001b[38;5;241m=\u001b[39m description()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tables/description.py:524\u001b[0m, in \u001b[0;36mDescription.__init__\u001b[0;34m(self, classdict, nestedlvl, validate, ptparams)\u001b[0m\n\u001b[1;32m    522\u001b[0m newdict[k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m    \u001b[38;5;66;03m# To allow natural naming\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mobject\u001b[39m, (Col, Description)):\n\u001b[0;32m--> 524\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPassing an incorrect value to a table column.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    525\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Expected a Col (or subclass) instance and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    526\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgot: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. Please make use of the Col(), or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    527\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescendant, constructor to properly \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    528\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitialize columns.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m_v_pos \u001b[38;5;241m=\u001b[39m pos  \u001b[38;5;66;03m# Set the position of this object\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m_v_parent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# The parent description\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Passing an incorrect value to a table column. Expected a Col (or subclass) instance and got: \"ObjectAtom()\". Please make use of the Col(), or descendant, constructor to properly initialize columns."
     ]
    }
   ],
   "source": [
    "# Modify the DataFrame\n",
    "df.loc[0, 'A'] = 1\n",
    "\n",
    "# Ensure data types are compatible\n",
    "# We use float to avoid issues with NaN values in integer columns\n",
    "df = df.astype({'A': 'float64', 'B': 'float64'})\n",
    "\n",
    "# Persist the change by saving the DataFrame to an HDF5 store using the 'table' format\n",
    "with pd.HDFStore(\"data/store1.h5\", mode='w') as store:\n",
    "    store.put('df', df, format='table')\n",
    "\n",
    "# Load the store and show the first two rows to verify persistence\n",
    "with pd.HDFStore(\"data/store1.h5\", mode='r') as store:\n",
    "    persisted_df = store['df']\n",
    "    print(persisted_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing data on the web and in the cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 8] nodename nor servname provided, or not known>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[1;32m   1349\u001b[0m               encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/http/client.py:1294\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1294\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/http/client.py:1340\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1339\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders(body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/http/client.py:1289\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1289\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/http/client.py:1048\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1048\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1051\u001b[0m \n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/http/client.py:986\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 986\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/http/client.py:952\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    951\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[0;32m--> 952\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection(\n\u001b[1;32m    953\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address)\n\u001b[1;32m    954\u001b[0m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/socket.py:827\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[1;32m    826\u001b[0m exceptions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 827\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m getaddrinfo(host, port, \u001b[38;5;241m0\u001b[39m, SOCK_STREAM):\n\u001b[1;32m    828\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/socket.py:962\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    961\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 962\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m _socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, \u001b[38;5;28mtype\u001b[39m, proto, flags):\n\u001b[1;32m    963\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# read csv directly from Yahoo! Finance from a URL\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://ichart.yahoo.com/table.csv?s=MSFT&\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m      3\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma=5&b=1&c=2014&\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m      4\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md=5&e=30&f=2014&\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m      5\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mg=d&ignore=.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m df[:\u001b[38;5;241m5\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:586\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    571\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    572\u001b[0m     dialect,\n\u001b[1;32m    573\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    583\u001b[0m )\n\u001b[1;32m    584\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:482\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    479\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:811\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwds:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1040\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown engine: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (valid options are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1038\u001b[0m     )\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:51\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     48\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musecols\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musecols\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# open handles\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_handles(src, kwds)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Have to pass int, would break tests using TextReader directly otherwise :(\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/base_parser.py:222\u001b[0m, in \u001b[0;36mParserBase._open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_handles\u001b[39m(\u001b[38;5;28mself\u001b[39m, src: FilePathOrBuffer, kwds: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m    Let the readers open IOHandles after they are done with their potential raises.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m    223\u001b[0m         src,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mkwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    226\u001b[0m         compression\u001b[38;5;241m=\u001b[39mkwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    227\u001b[0m         memory_map\u001b[38;5;241m=\u001b[39mkwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    228\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mkwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    229\u001b[0m         errors\u001b[38;5;241m=\u001b[39mkwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    230\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:609\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid value for `encoding_errors` (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merrors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). Please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.python.org/3/library/codecs.html#error-handlers \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor valid values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m     )\n\u001b[1;32m    608\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 609\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m _get_filepath_or_buffer(\n\u001b[1;32m    610\u001b[0m     path_or_buf,\n\u001b[1;32m    611\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m    612\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m    613\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    614\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    615\u001b[0m )\n\u001b[1;32m    617\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    618\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[Buffer]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:312\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    311\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urlopen(req_info) \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    313\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:212\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(req, data)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_open, protocol, protocol \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    537\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m'\u001b[39m, req)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/urllib/request.py:1377\u001b[0m, in \u001b[0;36mHTTPHandler.http_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_open(http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPConnection, req)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/urllib/request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[1;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 8] nodename nor servname provided, or not known>"
     ]
    }
   ],
   "source": [
    "# read csv directly from Yahoo! Finance from a URL\n",
    "df = pd.read_csv(\"http://ichart.yahoo.com/table.csv?s=MSFT&\" +\n",
    "                 \"a=5&b=1&c=2014&\" +\n",
    "                 \"d=5&e=30&f=2014&\" +\n",
    "                 \"g=d&ignore=.csv\")\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and writing from/to SQL databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:2872: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  sql.to_sql(\n"
     ]
    }
   ],
   "source": [
    "# reference SQLite\n",
    "import sqlite3\n",
    "\n",
    "# read in the stock data from CSV\n",
    "msft = pd.read_csv(\"data/msft.csv\")\n",
    "msft[\"Symbol\"]=\"MSFT\"\n",
    "aapl = pd.read_csv(\"data/aapl.csv\")\n",
    "aapl[\"Symbol\"]=\"AAPL\"\n",
    "\n",
    "# create connection\n",
    "connection = sqlite3.connect(\"data/stocks.sqlite\")\n",
    "# .to_sql() will create SQL to store the DataFrame\n",
    "# in the specified table.  if_exists specifies\n",
    "# what to do if the table already exists\n",
    "msft.to_sql(\"STOCK_DATA\", connection, if_exists=\"replace\")\n",
    "aapl.to_sql(\"STOCK_DATA\", connection, if_exists=\"append\")\n",
    "\n",
    "# commit the SQL and close the connection\n",
    "connection.commit()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Date   Open   High    Low  Close   Volume  Adj Close Symbol\n",
       "index                                                                   \n",
       "0      2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93   MSFT\n",
       "1      2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35   MSFT\n",
       "2      2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63   MSFT\n",
       "3      2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91   MSFT\n",
       "4      2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58   MSFT"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to the database file\n",
    "connection = sqlite3.connect(\"data/stocks.sqlite\")\n",
    "\n",
    "# query all records in STOCK_DATA\n",
    "# returns a DataFrame\n",
    "# inde_col specifies which column to make the DataFrame index\n",
    "stocks = pd.io.sql.read_sql(\"SELECT * FROM STOCK_DATA;\", \n",
    "                             connection, index_col='index')\n",
    "\n",
    "# close the connection\n",
    "connection.close()\n",
    "\n",
    "# report the head of the data retrieved\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Date   Open   High    Low  Close    Volume  Adj Close Symbol\n",
       "index                                                                    \n",
       "1081   2010-05-21  42.22  42.35  40.99  42.00  33610800      36.48   MSFT\n",
       "1097   2010-04-29  46.80  46.95  44.65  45.92  47076200      38.41   MSFT\n",
       "1826   2007-06-15  89.80  92.10  89.55  92.04  30656400      35.87   MSFT\n",
       "3455   2001-03-16  47.00  47.80  46.10  45.33  40806400      17.66   MSFT\n",
       "3712   2000-03-17  49.50  50.00  48.29  50.00  50860500      19.48   MSFT"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the connection\n",
    "connection = sqlite3.connect(\"data/stocks.sqlite\")\n",
    "\n",
    "# construct the query string\n",
    "query = \"SELECT * FROM STOCK_DATA WHERE Volume>29200100 AND Symbol='MSFT';\"\n",
    "\n",
    "# execute and close connection\n",
    "items = pd.io.sql.read_sql(query, connection, index_col='index')\n",
    "connection.close()\n",
    "\n",
    "# report the query result\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data from remote data services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading stock data from Yahoo! and Google Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ping An Insurance (601318.SS) Data:\n",
      "                 Open       High        Low      Close  Adj Close     Volume\n",
      "Date                                                                        \n",
      "2010-01-04  27.745001  27.795000  26.915001  26.945000  19.675257   58728024\n",
      "2010-01-05  27.014999  27.600000  26.405001  27.285000  19.923519   72031524\n",
      "2010-01-06  27.200001  27.450001  26.650000  26.705000  19.500008   66409204\n",
      "2010-01-07  26.700001  26.905001  25.934999  26.209999  19.138559   73083638\n",
      "2010-01-08  26.209999  26.209999  25.650000  26.055000  19.025373   64604364\n",
      "...               ...        ...        ...        ...        ...        ...\n",
      "2015-08-17  33.410000  33.490002  32.599998  32.970001  25.745945  152170414\n",
      "2015-08-18  33.029999  33.630001  31.240000  31.290001  24.434052  210389448\n",
      "2015-08-19  30.950001  31.639999  30.500000  31.410000  24.527752  161453342\n",
      "2015-08-20  31.000000  31.400000  30.520000  30.549999  23.856190  109864022\n",
      "2015-08-21  30.459999  31.150000  29.299999  29.389999  22.950357  205858189\n",
      "\n",
      "[1370 rows x 6 columns]\n",
      "\n",
      "Microsoft (MSFT) Data Head:\n",
      "                 Open       High        Low      Close  Adj Close    Volume\n",
      "Date                                                                       \n",
      "2010-01-04  30.620001  31.100000  30.590000  30.950001  23.389406  38409100\n",
      "2010-01-05  30.850000  31.100000  30.639999  30.959999  23.396952  49749600\n",
      "2010-01-06  30.879999  31.080000  30.520000  30.770000  23.253374  58182400\n",
      "2010-01-07  30.629999  30.700001  30.190001  30.450001  23.011547  50559700\n",
      "2010-01-08  30.280001  30.879999  30.240000  30.660000  23.170246  51197400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Set the start and end dates\n",
    "start = datetime.datetime(2010, 1, 1)\n",
    "end = datetime.datetime(2015, 8, 22)\n",
    "\n",
    "# Fetch stock data for '601318.SS' (Ping An Insurance, Shanghai Stock Exchange)\n",
    "df = yf.download('601318.SS', start=start, end=end)\n",
    "print(\"Ping An Insurance (601318.SS) Data:\")\n",
    "print(df)\n",
    "\n",
    "# Fetch MSFT stock data from Yahoo! Finance and view the head\n",
    "yahoo = yf.download('MSFT', start=start, end=end)\n",
    "print(\"\\nMicrosoft (MSFT) Data Head:\")\n",
    "print(yahoo.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Open       High        Low      Close  Adj Close    Volume\n",
      "Date                                                                       \n",
      "2010-01-04  30.620001  31.100000  30.590000  30.950001  23.389406  38409100\n",
      "2010-01-05  30.850000  31.100000  30.639999  30.959999  23.396952  49749600\n",
      "2010-01-06  30.879999  31.080000  30.520000  30.770000  23.253374  58182400\n",
      "2010-01-07  30.629999  30.700001  30.190001  30.450001  23.011547  50559700\n",
      "2010-01-08  30.280001  30.879999  30.240000  30.660000  23.170246  51197400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# Set the start and end dates\n",
    "start = datetime.datetime(2010, 1, 1)\n",
    "end = datetime.datetime(2015, 8, 22)\n",
    "\n",
    "# Fetch MSFT stock data from Yahoo! Finance using yfinance\n",
    "msft = yf.download(\"MSFT\", start=start, end=end)\n",
    "\n",
    "# Display the head of the data\n",
    "print(msft.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving options data from Yahoo! Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Open      High       Low     Close\n",
      "Date                                                             \n",
      "1980-12-12 00:00:00-05:00  0.099058  0.099488  0.099058  0.099058\n",
      "1980-12-15 00:00:00-05:00  0.094320  0.094320  0.093890  0.093890\n",
      "1980-12-16 00:00:00-05:00  0.087429  0.087429  0.086998  0.086998\n",
      "1980-12-17 00:00:00-05:00  0.089152  0.089582  0.089152  0.089152\n",
      "1980-12-18 00:00:00-05:00  0.091737  0.092167  0.091737  0.091737\n",
      "1980-12-19 00:00:00-05:00  0.097335  0.097766  0.097335  0.097335\n",
      "\n",
      "Options data (calls):\n",
      "        contractSymbol             lastTradeDate  strike  lastPrice  bid  ...  \\\n",
      "0  AAPL240628C00100000 2024-06-21 16:55:49+00:00   100.0     110.25  0.0  ...   \n",
      "1  AAPL240628C00105000 2024-06-12 19:43:32+00:00   105.0     110.11  0.0  ...   \n",
      "2  AAPL240628C00110000 2024-06-21 19:41:29+00:00   110.0     100.06  0.0  ...   \n",
      "3  AAPL240628C00125000 2024-06-21 19:08:36+00:00   125.0      85.74  0.0  ...   \n",
      "4  AAPL240628C00130000 2024-06-21 18:02:20+00:00   130.0      80.36  0.0  ...   \n",
      "\n",
      "   openInterest  impliedVolatility  inTheMoney  contractSize  currency  \n",
      "0             0            0.00001        True       REGULAR       USD  \n",
      "1             0            0.00001        True       REGULAR       USD  \n",
      "2             0            0.00001        True       REGULAR       USD  \n",
      "3             0            0.00001        True       REGULAR       USD  \n",
      "4             0            0.00001        True       REGULAR       USD  \n",
      "\n",
      "[5 rows x 14 columns]\n",
      "\n",
      "Options data (puts):\n",
      "        contractSymbol             lastTradeDate  strike  lastPrice  bid  ...  \\\n",
      "0  AAPL240628P00100000 2024-06-25 13:30:05+00:00   100.0       0.01  0.0  ...   \n",
      "1  AAPL240628P00110000 2024-06-21 19:59:52+00:00   110.0       0.01  0.0  ...   \n",
      "2  AAPL240628P00115000 2024-06-26 13:30:21+00:00   115.0       0.01  0.0  ...   \n",
      "3  AAPL240628P00125000 2024-06-24 15:10:37+00:00   125.0       0.01  0.0  ...   \n",
      "4  AAPL240628P00130000 2024-06-24 19:37:04+00:00   130.0       0.01  0.0  ...   \n",
      "\n",
      "   openInterest  impliedVolatility  inTheMoney  contractSize  currency  \n",
      "0             0           0.500005       False       REGULAR       USD  \n",
      "1             0           0.500005       False       REGULAR       USD  \n",
      "2             0           0.500005       False       REGULAR       USD  \n",
      "3             0           0.500005       False       REGULAR       USD  \n",
      "4             0           0.500005       False       REGULAR       USD  \n",
      "\n",
      "[5 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Fetch AAPL stock data from Yahoo! Finance\n",
    "aapl = yf.Ticker('AAPL')\n",
    "\n",
    "# Get historical market data\n",
    "hist = aapl.history(period=\"max\")\n",
    "\n",
    "# Examine the first six rows and four columns\n",
    "print(hist.iloc[0:6, 0:4])\n",
    "\n",
    "# Fetch options data (optional, and can take time)\n",
    "options = aapl.option_chain()\n",
    "print(\"\\nOptions data (calls):\")\n",
    "print(options.calls.head())\n",
    "print(\"\\nOptions data (puts):\")\n",
    "print(options.puts.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [contractSymbol, lastTradeDate, strike, lastPrice]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch AAPL stock data from Yahoo! Finance\n",
    "aapl = yf.Ticker('AAPL')\n",
    "\n",
    "# Fetch options data\n",
    "options = aapl.option_chain()\n",
    "\n",
    "# Filter for puts at a strike price of $80\n",
    "puts_at_80 = options.puts[options.puts['strike'] == 80]\n",
    "\n",
    "# Display the first five rows and the first four columns\n",
    "print(puts_at_80.iloc[0:5, 0:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch AAPL stock data from Yahoo! Finance\n",
    "aapl = yf.Ticker('AAPL')\n",
    "\n",
    "# Fetch all expiration dates for options\n",
    "all_expiration_dates = aapl.options\n",
    "\n",
    "# Initialize an empty DataFrame to store the filtered puts options\n",
    "filtered_puts = pd.DataFrame()\n",
    "\n",
    "# Define the date range\n",
    "start_date = '2015-01-17'\n",
    "end_date = '2015-04-17'\n",
    "\n",
    "# Fetch options data for each expiration date within the specified range\n",
    "for exp_date in all_expiration_dates:\n",
    "    if start_date <= exp_date <= end_date:\n",
    "        options = aapl.option_chain(exp_date)\n",
    "        puts_at_80 = options.puts[options.puts['strike'] == 80]\n",
    "        filtered_puts = pd.concat([filtered_puts, puts_at_80])\n",
    "\n",
    "# Display the filtered data (first 5 rows and first 4 columns)\n",
    "print(filtered_puts.iloc[:, 0:4].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching options data: Expiration `2015-01-05` cannot be found. Available expirations are: [2024-06-28, 2024-07-05, 2024-07-12, 2024-07-19, 2024-07-26, 2024-08-02, 2024-08-16, 2024-09-20, 2024-10-18, 2024-11-15, 2024-12-20, 2025-01-17, 2025-03-21, 2025-06-20, 2025-09-19, 2025-12-19, 2026-01-16, 2026-06-18, 2026-12-18]\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Set the expiration date\n",
    "expiry = '2015-01-05'\n",
    "\n",
    "# Fetch MSFT stock data from Yahoo! Finance\n",
    "msft = yf.Ticker('MSFT')\n",
    "\n",
    "# Fetch the call options data for the specified expiration date\n",
    "try:\n",
    "    options = msft.option_chain(expiry)\n",
    "    msft_calls = options.calls\n",
    "    print(\"MSFT Calls expiring on 2015-01-05:\")\n",
    "    print(msft_calls.iloc[0:5, 0:5])\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching options data: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching options data: Expiration `2015-01-05` cannot be found. Available expirations are: [2024-06-28, 2024-07-05, 2024-07-12, 2024-07-19, 2024-07-26, 2024-08-02, 2024-08-16, 2024-09-20, 2024-10-18, 2024-11-15, 2024-12-20, 2025-01-17, 2025-03-21, 2025-06-20, 2025-09-19, 2025-12-19, 2026-01-16, 2026-06-18, 2026-12-18]\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Set the expiration date\n",
    "expiry = '2015-01-05'\n",
    "\n",
    "# Fetch MSFT stock data from Yahoo! Finance\n",
    "msft = yf.Ticker('MSFT')\n",
    "\n",
    "# Fetch the call options data for the specified expiration date\n",
    "try:\n",
    "    options = msft.option_chain(expiry)\n",
    "    msft_calls = options.calls\n",
    "    print(\"MSFT Calls expiring on 2015-01-05:\")\n",
    "    print(msft_calls.iloc[0:5, 0:5])\n",
    "except Exception as e:\n",
    "    print(f\"Error fetching options data: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading economic data from the Federal Reserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  GDP\n",
       "DATE                 \n",
       "2012-01-01  16068.805\n",
       "2012-04-01  16207.115\n",
       "2012-07-01  16319.541\n",
       "2012-10-01  16420.419\n",
       "2013-01-01  16648.189\n",
       "2013-04-01  16728.687\n",
       "2013-07-01  16953.838\n",
       "2013-10-01  17192.019\n",
       "2014-01-01  17197.738"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read GDP data from FRED\n",
    "gdp = web.DataReader(\"GDP\", \"fred\", \n",
    "                     datetime.date(2012, 1, 1), \n",
    "                     datetime.date(2014, 1, 27))\n",
    "gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            A576RC1A027NBEA\n",
       "DATE                       \n",
       "1929-01-01             50.5\n",
       "1930-01-01             46.2\n",
       "1931-01-01             39.2\n",
       "1932-01-01             30.5\n",
       "1933-01-01             29.0\n",
       "...                     ...\n",
       "2009-01-01           6251.4\n",
       "2010-01-01           6377.5\n",
       "2011-01-01           6633.2\n",
       "2012-01-01           6930.3\n",
       "2013-01-01           7114.4\n",
       "\n",
       "[85 rows x 1 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Compensation of employees: Wages and salaries\n",
    "web.DataReader(\"A576RC1A027NBEA\",\"fred\", datetime.date(1929, 1, 1), datetime.date(2013, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Kenneth French data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: Empty DataFrame\n",
       " Columns: [Mkt-RF, SMB, HML, WML, RF]\n",
       " Index: [],\n",
       " 1: Empty DataFrame\n",
       " Columns: [Mkt-RF, SMB, HML, WML, RF]\n",
       " Index: [],\n",
       " 'DESCR': 'Global Factors\\n--------------\\n\\nThis file was created using the 201601 Bloomberg database. Missing data are indicated by -99.99. \\n\\n  0 : (0 rows x 5 cols)\\n  1 : Annual Factors: January-December (0 rows x 5 cols)'}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read from Kenneth French fama global factors data set\n",
    "factors = web.DataReader(\"Global_Factors\", \"famafrench\")\n",
    "factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from the World Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     id                                     name unit  \\\n",
      "0    1.0.HCount.1.90usd          Poverty Headcount ($1.90 a day)        \n",
      "1     1.0.HCount.2.5usd          Poverty Headcount ($2.50 a day)        \n",
      "2  1.0.HCount.Mid10to50    Middle Class ($10-50 a day) Headcount        \n",
      "3       1.0.HCount.Ofcl  Official Moderate Poverty Rate-National        \n",
      "4   1.0.HCount.Poor4uds             Poverty Headcount ($4 a day)        \n",
      "\n",
      "           source                                         sourceNote  \\\n",
      "0  LAC Equity Lab  The poverty headcount index measures the propo...   \n",
      "1  LAC Equity Lab  The poverty headcount index measures the propo...   \n",
      "2  LAC Equity Lab  The poverty headcount index measures the propo...   \n",
      "3  LAC Equity Lab  The poverty headcount index measures the propo...   \n",
      "4  LAC Equity Lab  The poverty headcount index measures the propo...   \n",
      "\n",
      "                                  sourceOrganization    topics  \n",
      "0  b'LAC Equity Lab tabulations of SEDLAC (CEDLAS...  Poverty   \n",
      "1  b'LAC Equity Lab tabulations of SEDLAC (CEDLAS...  Poverty   \n",
      "2  b'LAC Equity Lab tabulations of SEDLAC (CEDLAS...  Poverty   \n",
      "3  b'LAC Equity Lab tabulations of data from Nati...  Poverty   \n",
      "4  b'LAC Equity Lab tabulations of SEDLAC (CEDLAS...  Poverty   \n"
     ]
    }
   ],
   "source": [
    "from pandas_datareader import wb\n",
    "import pandas as pd\n",
    "\n",
    "# Get all indicators\n",
    "all_indicators = wb.get_indicators()\n",
    "\n",
    "# Display the first few indicators\n",
    "print(all_indicators.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     id\n",
      "0    1.0.HCount.1.90usd\n",
      "1     1.0.HCount.2.5usd\n",
      "2  1.0.HCount.Mid10to50\n",
      "3       1.0.HCount.Ofcl\n",
      "4   1.0.HCount.Poor4uds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get all indicators\n",
    "all_indicators = wb.get_indicators()\n",
    "\n",
    "# Examine the first few indicators\n",
    "print(all_indicators.iloc[:, 0:1].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   id                                               name\n",
       "15862     SE.SCH.LIFE  School life expectancy, primary to tertiary, b...\n",
       "15863  SE.SCH.LIFE.FE  School life expectancy, primary to tertiary, f...\n",
       "15864  SE.SCH.LIFE.MA  School life expectancy, primary to tertiary, m..."
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search of life expectancy indicators\n",
    "le_indicators = wb.search(\"life expectancy\")\n",
    "# report first three rows, first two columns\n",
    "le_indicators.iloc[:3,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          name       capitalCity iso2c\n",
      "0                        Aruba        Oranjestad    AW\n",
      "1  Africa Eastern and Southern                      ZH\n",
      "2                  Afghanistan             Kabul    AF\n",
      "3                       Africa                      A9\n",
      "4   Africa Western and Central                      ZI\n",
      "5                       Angola            Luanda    AO\n",
      "6                      Albania            Tirane    AL\n",
      "7                      Andorra  Andorra la Vella    AD\n",
      "8                   Arab World                      1A\n",
      "9         United Arab Emirates         Abu Dhabi    AE\n"
     ]
    }
   ],
   "source": [
    "from pandas_datareader import wb\n",
    "import pandas as pd\n",
    "\n",
    "# Get countries\n",
    "countries = wb.get_countries()\n",
    "\n",
    "# Show a subset of the country data (name, capitalCity, iso2c)\n",
    "subset = countries.loc[:, ['name', 'capitalCity', 'iso2c']].head(10)\n",
    "\n",
    "print(subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    SP.DYN.LE00.IN\n",
       "country       year                \n",
       "Canada        2014       81.784390\n",
       "              2013       81.744878\n",
       "              2012       81.663659\n",
       "              2011       81.482683\n",
       "              2010       81.322195\n",
       "...                            ...\n",
       "United States 1984       74.563415\n",
       "              1983       74.463415\n",
       "              1982       74.360976\n",
       "              1981       74.009756\n",
       "              1980       73.609756\n",
       "\n",
       "[105 rows x 1 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get life expectancy at birth for all countries from 1980 to 2014\n",
    "le_data_all = wb.download(indicator=\"SP.DYN.LE00.IN\", \n",
    "                          start='1980', \n",
    "                          end='2014')\n",
    "le_data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Canada', 'Mexico', 'United States'], dtype='object', name='country')"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only US, CAN, and MEX are returned by default\n",
    "le_data_all.index.levels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/pandas_datareader/wb.py:592: UserWarning: Non-standard ISO country codes: 1A, 1W, 4E, 6F, 6N, 6X, 7E, 8S, A4, A5, A9, B1, B2, B3, B4, B6, B7, B8, C4, C5, C6, C7, C8, C9, D2, D3, D4, D5, D6, D7, EU, F1, F6, JG, M1, M2, N6, OE, R6, S1, S2, S3, S4, T2, T3, T4, T5, T6, T7, V1, V2, V3, V4, XC, XD, XE, XF, XG, XH, XI, XJ, XK, XL, XM, XN, XO, XP, XQ, XT, XU, XY, Z4, Z7, ZB, ZF, ZG, ZH, ZI, ZJ, ZQ, ZT\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "               SP.DYN.LE00.IN\n",
       "country  year                \n",
       "Aruba    2012          75.531\n",
       "         2011          75.465\n",
       "         2010          75.404\n",
       "         2009          74.560\n",
       "         2008          74.147\n",
       "...                       ...\n",
       "Zimbabwe 1984          61.051\n",
       "         1983          60.248\n",
       "         1982          59.875\n",
       "         1981          59.327\n",
       "         1980          58.674\n",
       "\n",
       "[8778 rows x 1 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve life expectancy at birth for all countries \n",
    "# from 1980 to 2014\n",
    "le_data_all = wb.download(indicator=\"SP.DYN.LE00.IN\", \n",
    "                          country = countries['iso2c'],\n",
    "                          start='1980', \n",
    "                          end='2012')\n",
    "le_data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                            SP.DYN.LE00.IN                      \n",
       "year                                  1980       1981       1982\n",
       "country                                                         \n",
       "Afghanistan                      39.618000  40.164000  37.766000\n",
       "Africa Eastern and Southern      49.636538  50.057073  50.296849\n",
       "Africa Western and Central       47.015239  47.297190  47.529378\n",
       "Albania                          70.478000  70.730000  71.023000\n",
       "Algeria                          53.261000  55.276000  57.428000\n",
       "...                                    ...        ...        ...\n",
       "West Bank and Gaza                     NaN        NaN        NaN\n",
       "World                            62.233533  62.611312  62.972225\n",
       "Yemen, Rep.                      50.654000  51.709000  52.405000\n",
       "Zambia                           54.143000  54.047000  53.859000\n",
       "Zimbabwe                         58.674000  59.327000  59.875000\n",
       "\n",
       "[266 rows x 3 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#le_data_all.pivot(index='country', columns='year')\n",
    "le_data = le_data_all.reset_index().pivot(index='country', \n",
    "                                          columns='year')\n",
    "# examine pivoted data\n",
    "le_data.iloc[:, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                year\n",
       "SP.DYN.LE00.IN  1980    Timor-Leste\n",
       "                1981    Timor-Leste\n",
       "                1982    Timor-Leste\n",
       "                1983    Timor-Leste\n",
       "                1984    South Sudan\n",
       "                           ...     \n",
       "                2008        Lesotho\n",
       "                2009        Lesotho\n",
       "                2010        Lesotho\n",
       "                2011        Lesotho\n",
       "                2012        Lesotho\n",
       "Length: 33, dtype: object"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ask what is the name of country for each year\n",
    "# with the least life expectancy\n",
    "country_with_least_expectancy = le_data.idxmin(axis=0)\n",
    "country_with_least_expectancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                year\n",
       "SP.DYN.LE00.IN  1980    28.446\n",
       "                1981    29.567\n",
       "                1982    30.824\n",
       "                1983    31.635\n",
       "                1984    32.673\n",
       "                         ...  \n",
       "                2008    43.566\n",
       "                2009    44.034\n",
       "                2010    45.596\n",
       "                2011    46.692\n",
       "                2012    47.835\n",
       "Length: 33, dtype: float64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and what is the minimum life expectancy for each year\n",
    "expectancy_for_least_country = le_data.min(axis=0)\n",
    "expectancy_for_least_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Country  Expectancy\n",
      "(2010, Country1)  Country1        50.5\n",
      "(2011, Country2)  Country2        52.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data assuming you have these Series or DataFrames\n",
    "# Replace these with your actual data\n",
    "country_with_least_expectancy = pd.Series(['Country1', 'Country2'], index=[(2010, 'Country1'), (2011, 'Country2')])\n",
    "expectancy_for_least_country = pd.Series([50.5, 52.3], index=[(2010, 'Country1'), (2011, 'Country2')])\n",
    "\n",
    "# Create the DataFrame\n",
    "least = pd.DataFrame(\n",
    "    data={\n",
    "        'Country': country_with_least_expectancy.values,\n",
    "        'Expectancy': expectancy_for_least_country.values\n",
    "    },\n",
    "    index=country_with_least_expectancy.index.get_level_values(0)  # Assuming the index is a MultiIndex\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(least)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
